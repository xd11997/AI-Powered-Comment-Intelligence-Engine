{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7cab306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking is done\n",
      "LLM summaries for all chunks are done. total=6 failed=0. failed indices=[]\n",
      "[(\"Jimin's funny expressions\", 6), (\"Taehyung's eyes\", 4), ('BTS', 2), (\"Namjoon's leadership\", 2), ('Suga', 2)]\n",
      "[('Bilingual fans (comments in multiple languages)', 4), ('Audience members expressing emotional connections to BTS', 4), ('International ARMY fans', 3)]\n",
      "[(\"Emotional connection to BTS's music and performances\", 6), ('Humor and comedic moments from the members', 6)]\n",
      "[('Desire for more content and longer versions of videos', 4), (\"Frustration with the lack of recognition for BTS's contributions\", 2)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 把项目根目录加入 Python path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.data_loader import load_comments\n",
    "from src.chunking import chunk_comments\n",
    "from src.llm_extraction_v2 import extract_insights_from_chunk\n",
    "from src.aggregation import aggregate_insights_with_clustering\n",
    "\n",
    "comments = load_comments(\"../data/bts_comments.csv\")\n",
    "chunks = chunk_comments(comments, chunk_size=500)\n",
    "\n",
    "print(\"Chunking is done\")\n",
    "\n",
    "#（并发）\n",
    "from src.parsing import robust_parse\n",
    "import concurrent.futures\n",
    "\n",
    "group_results = []\n",
    "failed = []\n",
    "\n",
    "def process_chunk(i_chunk):\n",
    "    i, chunk = i_chunk\n",
    "    raw_output = extract_insights_from_chunk(chunk)\n",
    "    parsed = robust_parse(raw_output, raise_on_fail=False)\n",
    "\n",
    "    if parsed is None:\n",
    "        with open(f\"debug_raw_chunk_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(str(raw_output))\n",
    "        return i, {\n",
    "            \"audience_interest_themes\": [],\n",
    "            \"positive_content_drivers\": [],\n",
    "            \"recurring_pain_points\": []\n",
    "        }, True\n",
    "    else:\n",
    "        return i, parsed, False\n",
    "\n",
    "\n",
    "# 选择chunk范围\n",
    "selected_chunks = list(enumerate(chunks[:6]))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(process_chunk, item) for item in selected_chunks]\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        i, result, is_failed = future.result()\n",
    "        group_results.append(result)\n",
    "        if is_failed:\n",
    "            failed.append(i)\n",
    "\n",
    "print(f\"LLM summaries for all chunks are done. total={len(group_results)} failed={len(failed)}. failed indices={failed}\")\n",
    "\n",
    "final = aggregate_insights_with_clustering(group_results, eps=0.35)\n",
    "print(final['top_content_elements'])\n",
    "print(final['top_audience_insights'])\n",
    "print(final['top_engagement_drivers'])\n",
    "print(final['top_audience_pain_points'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670a23c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.31901039720844243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "\n",
    "# 1️⃣ 收集所有 phrase（比如 content_elements）\n",
    "items = []\n",
    "for res in group_results:\n",
    "    for phrase in res.get(\"content_elements\", []):\n",
    "        if phrase and phrase.strip():\n",
    "            items.append(phrase.strip())\n",
    "\n",
    "texts = items\n",
    "\n",
    "# 2️⃣ 得到 embeddings\n",
    "from src.aggregation import get_embeddings\n",
    "embs = np.array(get_embeddings(texts))\n",
    "\n",
    "# 3️⃣ 计算距离矩阵\n",
    "dists = cosine_distances(embs)\n",
    "\n",
    "# 4️⃣ 重新跑 DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "clustering = DBSCAN(eps=0.35, min_samples=1, metric=\"precomputed\")\n",
    "labels = clustering.fit_predict(dists)\n",
    "\n",
    "# 5️⃣ 去掉 noise\n",
    "mask = labels != -1\n",
    "\n",
    "filtered_labels = labels[mask]\n",
    "filtered_dists = dists[mask][:, mask]\n",
    "\n",
    "# 6️⃣ 检查是否至少2个cluster\n",
    "if len(set(filtered_labels)) > 1:\n",
    "    score = silhouette_score(filtered_dists, filtered_labels, metric=\"precomputed\")\n",
    "    print(\"Silhouette Score:\", score)\n",
    "else:\n",
    "    print(\"Cannot compute silhouette score (only one cluster)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f29c5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'silhouette_score_mean: 0.2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'silhouette_score_std: 0.09'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#不固定随机种子和并发顺序的情况下，跑了5次测得silhouette scores\n",
    "import pandas as pd\n",
    "\n",
    "silhouette_score = pd.DataFrame({\"result\":[0.25, 0.17, 0.17, 0.09, 0.32]})\n",
    "silhouette_score_mean = silhouette_score.mean()\n",
    "silhouette_score_std = silhouette_score.std()\n",
    "\n",
    "display(f\"silhouette_score_mean: {silhouette_score_mean['result'].round(2)}\", f\"silhouette_score_std: {silhouette_score_std['result'].round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc77988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking is done\n",
      "[{'content_elements': [\"Jungkook's cute moments\", \"BTS's brotherhood\", \"Jin's humor\", \"Taehyung's unique personality\", \"Jimin's dance skills\"], 'audience_identity_signals': ['New ARMY members', 'Fans expressing cultural connections', 'International audience from various countries'], 'engagement_drivers': [\"Relatability to BTS's struggles and growth\", 'Humor in interactions and comments', \"Emotional connection to members' personalities\"], 'audience_painpoints': ['Desire for more BTS content', 'Frustration with negative comments about BTS', \"Concerns about members' well-being during military service\"]}, {'content_elements': [\"Jin's humor\", \"Jungkook's cuteness\", \"BTS's camaraderie\", \"Hobi's dancing skills\", \"Suga's savage moments\"], 'audience_identity_signals': ['Fans expressing deep emotional connections to BTS', 'International audience with diverse languages and cultures', 'Younger audience members, including teens and children'], 'engagement_drivers': ['Relatability through shared experiences and emotions', \"Humor in BTS's interactions and moments\", \"Nostalgia for BTS's earlier music and performances\"], 'audience_painpoints': 'N/A'}, {'content_elements': [\"BTS members' interactions\", \"Jungkook's vocal abilities\", \"Taehyung's charm and looks\", \"Namjoon's leadership qualities\", 'Humorous moments in BTS videos'], 'audience_identity_signals': ['International ARMY fans', 'Fans who appreciate K-pop and dance', 'Viewers who express emotional connections to BTS'], 'engagement_drivers': ['Relatability through shared experiences and humor', 'Emotional connections to the members and their stories', 'Participatory prompts inviting fans to share their thoughts'], 'audience_painpoints': ['Frustration with how BTS and TXT are portrayed in media', 'Desire for more content featuring specific members', 'Concerns about the mental health of the members']}, {'content_elements': [\"Jungkook's tattoo\", \"Jin's dance\", \"BTS's music process\", \"Taehyung's voice\", \"Jimin's humor\"], 'audience_identity_signals': ['Fans from diverse backgrounds (e.g., Arabic, Indian, Turkish)', 'Younger audience (teenagers and young adults)', 'Long-time ARMY members expressing deep emotional connections'], 'engagement_drivers': ['Relatability through shared experiences and emotions', \"Humor and light-hearted moments in BTS's interactions\", \"Emotional storytelling in BTS's music and performances\"], 'audience_painpoints': 'N/A'}, {'content_elements': ['BTS', 'Jimin', 'Suga', 'Jungkook', 'Taehyung'], 'audience_identity_signals': ['Fans from diverse backgrounds (e.g., Arabic, Japanese, Spanish)', \"Long-term supporters of BTS (e.g., 'supporter here since day 1')\", 'Individuals expressing emotional connections to BTS members'], 'engagement_drivers': ['Humor and relatable moments (e.g., funny interactions between members)', \"Emotional storytelling (e.g., personal experiences tied to BTS's music)\", 'Community feeling among fans (e.g., shared experiences and support)'], 'audience_painpoints': 'N/A'}, {'content_elements': [\"Jungkook's cute moments\", \"BTS's camaraderie\", \"Jimin's character development\", \"Suga's rap skills\", \"Jin's humor\"], 'audience_identity_signals': ['Fans from diverse cultural backgrounds', 'New ARMY members', \"Individuals seeking emotional support through BTS's content\"], 'engagement_drivers': [\"Relatability to BTS's experiences and humor\", 'Emotional connection through shared struggles', \"Appreciation for BTS's talent and performances\"], 'audience_painpoints': ['Desire for more content and updates from BTS', \"Concerns about the members' well-being\", 'Frustration with misinformation about BTS']}]\n"
     ]
    }
   ],
   "source": [
    "comments = load_comments(\"../data/bts_comments.csv\")\n",
    "chunks = chunk_comments(comments, chunk_size=500)\n",
    "\n",
    "print(\"Chunking is done\")\n",
    "\n",
    "group_results = []\n",
    "failed = []\n",
    "\n",
    "def process_chunk(i_chunk):\n",
    "    i, chunk = i_chunk\n",
    "    raw_output = extract_insights_from_chunk(chunk)\n",
    "    parsed = robust_parse(raw_output, raise_on_fail=False)\n",
    "\n",
    "    if parsed is None:\n",
    "        with open(f\"debug_raw_chunk_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(str(raw_output))\n",
    "        return i, {\n",
    "            \"audience_interest_themes\": [],\n",
    "            \"positive_content_drivers\": [],\n",
    "            \"recurring_pain_points\": []\n",
    "        }, True\n",
    "    else:\n",
    "        return i, parsed, False\n",
    "\n",
    "\n",
    "# 选择chunk范围\n",
    "selected_chunks = list(enumerate(chunks[:6]))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(process_chunk, item) for item in selected_chunks]\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        i, result, is_failed = future.result()\n",
    "        group_results.append(result)\n",
    "        if is_failed:\n",
    "            failed.append(i)\n",
    "\n",
    "print(group_results)\n",
    "eval_dbscan = pd.DataFrame({\"group_results\": group_results})\n",
    "eval_dbscan.to_csv(\"../data/eval_dbscan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "203599e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total content_elements: 30\n",
      "[\"Jungkook's cute moments\", \"BTS's brotherhood\", \"Jin's humor\", \"Taehyung's unique personality\", \"Jimin's dance skills\", \"Jin's humor\", \"Jungkook's cuteness\", \"BTS's camaraderie\", \"Hobi's dancing skills\", \"Suga's savage moments\"]\n"
     ]
    }
   ],
   "source": [
    "# 提取 content_elements\n",
    "texts = []\n",
    "\n",
    "for res in group_results:\n",
    "    elems = res.get(\"content_elements\", [])\n",
    "    if isinstance(elems, list):\n",
    "        for t in elems:\n",
    "            if t and str(t).strip():\n",
    "                texts.append(str(t).strip())\n",
    "\n",
    "print(\"Total content_elements:\", len(texts))\n",
    "print(texts[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1a8b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (30, 1536)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.aggregation import get_embeddings\n",
    "\n",
    "embs = np.array(get_embeddings(texts))\n",
    "print(\"Embedding shape:\", embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfe1acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: 0.21873193522521206\n",
      "Run 2: 0.21873193522521206\n",
      "Run 3: 0.21873193522521206\n",
      "Run 4: 0.21873193522521206\n",
      "Run 5: 0.21873193522521206\n",
      "silhouette_score_mean: 0.22\n",
      "silhouette_score_std: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "scores = []\n",
    "\n",
    "for i in range(5):\n",
    "    dists = cosine_distances(embs)\n",
    "\n",
    "    clustering = DBSCAN(\n",
    "        eps=0.35,\n",
    "        min_samples=1,\n",
    "        metric=\"precomputed\"\n",
    "    )\n",
    "\n",
    "    labels = clustering.fit_predict(dists)\n",
    "\n",
    "    mask = labels != -1\n",
    "\n",
    "    if len(set(labels[mask])) > 1:\n",
    "        score = silhouette_score(\n",
    "            dists[mask][:, mask],\n",
    "            labels[mask],\n",
    "            metric=\"precomputed\"\n",
    "        )\n",
    "    else:\n",
    "        score = None\n",
    "\n",
    "    scores.append(score)\n",
    "    print(f\"Run {i+1}: {score}\")\n",
    "\n",
    "print(\"silhouette_score_mean:\", np.mean(scores).round(2))\n",
    "print(\"silhouette_score_std:\", np.std(scores).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06c9d9",
   "metadata": {},
   "source": [
    "### Variance decomposition is done\n",
    "#### Downstream clustering is stable. Variance mainly comes from upstream LLM summarization.\n",
    "- Pipeline-level silhouette: 0.20 ± 0.09 (n=5, full runs), which was high variance observed\n",
    "- Downstream test (fixed extracted phrases & embeddings): silhouette = 0.2187 (std = 0, n=5), which was downstream stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb43a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clusters: 15\n",
      "\n",
      "Cluster 0:\n",
      "  size = 4\n",
      "  avg cosine similarity = 0.7829\n",
      "  sample texts:\n",
      "   - Jungkook's cute moments\n",
      "   - Jungkook's cuteness\n",
      "   - Jungkook\n",
      "\n",
      "Cluster 1:\n",
      "  size = 4\n",
      "  avg cosine similarity = 0.7833\n",
      "  sample texts:\n",
      "   - BTS's brotherhood\n",
      "   - BTS's camaraderie\n",
      "   - BTS members' interactions\n",
      "\n",
      "Cluster 2:\n",
      "  size = 5\n",
      "  avg cosine similarity = 0.7012\n",
      "  sample texts:\n",
      "   - Jin's humor\n",
      "   - Jin's humor\n",
      "   - Jimin's humor\n",
      "\n",
      "Cluster 3:\n",
      "  size = 2\n",
      "  avg cosine similarity = 0.6574\n",
      "  sample texts:\n",
      "   - Taehyung's unique personality\n",
      "   - Taehyung's charm and looks\n",
      "\n",
      "Cluster 4:\n",
      "  size = 2\n",
      "  avg cosine similarity = 0.6850\n",
      "  sample texts:\n",
      "   - Jimin's dance skills\n",
      "   - Hobi's dancing skills\n",
      "\n",
      "Cluster 5:\n",
      "  size = 3\n",
      "  avg cosine similarity = 0.6558\n",
      "  sample texts:\n",
      "   - Suga's savage moments\n",
      "   - Suga\n",
      "   - Suga's rap skills\n",
      "\n",
      "Cluster 6: only 1 item (skip)\n",
      "Cluster 7: only 1 item (skip)\n",
      "Cluster 8: only 1 item (skip)\n",
      "Cluster 9: only 1 item (skip)\n",
      "Cluster 10: only 1 item (skip)\n",
      "Cluster 11: only 1 item (skip)\n",
      "Cluster 12:\n",
      "  size = 2\n",
      "  avg cosine similarity = 0.7097\n",
      "  sample texts:\n",
      "   - Taehyung's voice\n",
      "   - Taehyung\n",
      "\n",
      "Cluster 13: only 1 item (skip)\n",
      "Cluster 14: only 1 item (skip)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 重新计算 labels（确保和刚才一致）\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "dists = cosine_distances(embs)\n",
    "\n",
    "clustering = DBSCAN(\n",
    "    eps=0.35,\n",
    "    min_samples=1,\n",
    "    metric=\"precomputed\"\n",
    ")\n",
    "\n",
    "labels = clustering.fit_predict(dists)\n",
    "\n",
    "# -------- 计算每个 cluster 的内部平均相似度 --------\n",
    "\n",
    "cluster_dict = defaultdict(list)\n",
    "\n",
    "for idx, lab in enumerate(labels):\n",
    "    if lab != -1:  # 排除 noise\n",
    "        cluster_dict[lab].append(idx)\n",
    "\n",
    "print(\"Total clusters:\", len(cluster_dict))\n",
    "print()\n",
    "\n",
    "for lab, indices in cluster_dict.items():\n",
    "    \n",
    "    if len(indices) < 2:\n",
    "        print(f\"Cluster {lab}: only 1 item (skip)\")\n",
    "        continue\n",
    "    \n",
    "    cluster_embs = embs[indices]\n",
    "    \n",
    "    sim_matrix = cosine_similarity(cluster_embs)\n",
    "    \n",
    "    # 只取上三角（避免重复和对角线1）\n",
    "    n = len(indices)\n",
    "    upper_triangle = sim_matrix[np.triu_indices(n, k=1)]\n",
    "    \n",
    "    avg_sim = np.mean(upper_triangle)\n",
    "    \n",
    "    print(f\"Cluster {lab}:\")\n",
    "    print(f\"  size = {n}\")\n",
    "    print(f\"  avg cosine similarity = {avg_sim:.4f}\")\n",
    "    \n",
    "    # 可选：打印该cluster的文本\n",
    "    print(\"  sample texts:\")\n",
    "    for i in indices[:3]:\n",
    "        print(\"   -\", texts[i])\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca29ad2",
   "metadata": {},
   "source": [
    "### Sensitivity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bb06bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     eps  min_samples  silhouette  n_clusters  noise_ratio  mean_cohesion\n",
      "1   0.25            2    0.791385           3     0.666667       0.891090\n",
      "2   0.25            3    0.791385           3     0.666667       0.891090\n",
      "5   0.30            3    0.685606           3     0.600000       0.812199\n",
      "4   0.30            2    0.668814           4     0.533333       0.786581\n",
      "8   0.35            3    0.564029           4     0.466667       0.730782\n",
      "7   0.35            2    0.459048           7     0.266667       0.710749\n",
      "10  0.40            2    0.391564           5     0.066667       0.632583\n",
      "11  0.40            3    0.391564           5     0.066667       0.632583\n",
      "9   0.40            1    0.316881           7     0.000000       0.632583\n",
      "0   0.25            1    0.220895          23     0.000000       0.891090\n",
      "6   0.35            1    0.218732          15     0.000000       0.710749\n",
      "3   0.30            1    0.210039          20     0.000000       0.786581\n",
      "13  0.45            2    0.202170           3     0.033333       0.575247\n",
      "14  0.45            3    0.202170           3     0.033333       0.575247\n",
      "12  0.45            1    0.166189           4     0.000000       0.575247\n"
     ]
    }
   ],
   "source": [
    "# sensitivity_check.ipynb cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# 假设你已有：\n",
    "# embs: numpy array shape (n, d)\n",
    "# texts: list of strings aligned with embs\n",
    "\n",
    "EPS_LIST = [0.25, 0.30, 0.35, 0.40, 0.45]\n",
    "MIN_SAMPLES_LIST = [1, 2, 3]\n",
    "\n",
    "def eval_for_params(embs, eps, min_samples):\n",
    "    dists = cosine_distances(embs)\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"precomputed\")\n",
    "    labels = clustering.fit_predict(dists)\n",
    "    mask = labels != -1\n",
    "    # n_clusters excluding noise\n",
    "    n_clusters = len(set(labels[mask])) if mask.sum() > 0 else 0\n",
    "    noise_ratio = (labels == -1).sum() / len(labels)\n",
    "    sil = None\n",
    "    if n_clusters > 1:\n",
    "        sil = silhouette_score(dists[mask][:, mask], labels[mask], metric=\"precomputed\")\n",
    "    # cluster cohesion: avg of avg intra-cluster cosine similarity\n",
    "    cluster_indices = defaultdict(list)\n",
    "    for i, lab in enumerate(labels):\n",
    "        if lab != -1:\n",
    "            cluster_indices[lab].append(i)\n",
    "    cohesion_scores = []\n",
    "    for lab, idxs in cluster_indices.items():\n",
    "        if len(idxs) < 2:\n",
    "            continue\n",
    "        sims = cosine_similarity(embs[idxs])\n",
    "        upper = sims[np.triu_indices(len(idxs), k=1)]\n",
    "        cohesion_scores.append(np.mean(upper))\n",
    "    mean_cohesion = np.mean(cohesion_scores) if cohesion_scores else None\n",
    "    return dict(silhouette=sil, n_clusters=n_clusters, noise_ratio=noise_ratio, mean_cohesion=mean_cohesion, labels=labels)\n",
    "\n",
    "rows = []\n",
    "for eps in EPS_LIST:\n",
    "    for ms in MIN_SAMPLES_LIST:\n",
    "        r = eval_for_params(embs, eps=eps, min_samples=ms)\n",
    "        rows.append({\n",
    "            \"eps\": eps,\n",
    "            \"min_samples\": ms,\n",
    "            \"silhouette\": r[\"silhouette\"],\n",
    "            \"n_clusters\": r[\"n_clusters\"],\n",
    "            \"noise_ratio\": r[\"noise_ratio\"],\n",
    "            \"mean_cohesion\": r[\"mean_cohesion\"]\n",
    "        })\n",
    "df = pd.DataFrame(rows)\n",
    "# 方便查看：按 silhouette 排序\n",
    "print(df.sort_values([\"silhouette\"], ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ef68686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "DBSCAN Results (eps=0.25)\n",
      "============================\n",
      "\n",
      "Cluster 1 (size=4):\n",
      "  - BTS's brotherhood\n",
      "  - BTS's camaraderie\n",
      "  - BTS members' interactions\n",
      "  - BTS's camaraderie\n",
      "\n",
      "Cluster 0 (size=3):\n",
      "  - Jungkook's cute moments\n",
      "  - Jungkook's cuteness\n",
      "  - Jungkook's cute moments\n",
      "\n",
      "Cluster 2 (size=3):\n",
      "  - Jin's humor\n",
      "  - Jin's humor\n",
      "  - Jin's humor\n",
      "\n",
      "\n",
      "============================\n",
      "DBSCAN Results (eps=0.4)\n",
      "============================\n",
      "\n",
      "Cluster 2 (size=9):\n",
      "  - Jin's humor\n",
      "  - Jimin's dance skills\n",
      "  - Jin's humor\n",
      "  - Hobi's dancing skills\n",
      "  - Jin's dance\n",
      "  - Jimin's humor\n",
      "  - Jimin\n",
      "  - Jimin's character development\n",
      "  - Jin's humor\n",
      "\n",
      "Cluster 0 (size=6):\n",
      "  - Jungkook's cute moments\n",
      "  - Jungkook's cuteness\n",
      "  - Jungkook's vocal abilities\n",
      "  - Jungkook's tattoo\n",
      "  - Jungkook\n",
      "  - Jungkook's cute moments\n",
      "\n",
      "Cluster 1 (size=6):\n",
      "  - BTS's brotherhood\n",
      "  - BTS's camaraderie\n",
      "  - BTS members' interactions\n",
      "  - Humorous moments in BTS videos\n",
      "  - BTS\n",
      "  - BTS's camaraderie\n",
      "\n",
      "Cluster 3 (size=4):\n",
      "  - Taehyung's unique personality\n",
      "  - Taehyung's charm and looks\n",
      "  - Taehyung's voice\n",
      "  - Taehyung\n",
      "\n",
      "Cluster 4 (size=3):\n",
      "  - Suga's savage moments\n",
      "  - Suga\n",
      "  - Suga's rap skills\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from collections import defaultdict\n",
    "\n",
    "def show_clusters(embs, texts, eps, min_samples=1):\n",
    "    print(f\"\\n============================\")\n",
    "    print(f\"DBSCAN Results (eps={eps})\")\n",
    "    print(f\"============================\\n\")\n",
    "    \n",
    "    dists = cosine_distances(embs)\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"precomputed\")\n",
    "    labels = clustering.fit_predict(dists)\n",
    "    \n",
    "    cluster_dict = defaultdict(list)\n",
    "    for i, lab in enumerate(labels):\n",
    "        if lab != -1:\n",
    "            cluster_dict[lab].append(texts[i])\n",
    "    \n",
    "    # 按 cluster size 排序\n",
    "    sorted_clusters = sorted(cluster_dict.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    \n",
    "    for lab, items in sorted_clusters:\n",
    "        if len(items) < 2:\n",
    "            continue  # 跳过单个\n",
    "        \n",
    "        print(f\"Cluster {lab} (size={len(items)}):\")\n",
    "        for t in items:\n",
    "            print(\"  -\", t)\n",
    "        print()\n",
    "\n",
    "# 运行 0.25 和 0.40\n",
    "show_clusters(embs, texts, eps=0.25)\n",
    "show_clusters(embs, texts, eps=0.40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864fd22",
   "metadata": {},
   "source": [
    "### Trade offs\n",
    "Smaller eps (0.25) maximizes thematic granularity but increases fragmentation, while larger eps (0.40) produces more abstract, consolidated themes.\n",
    "To balance semantic precision and interpretability, this project adopts eps = 0.35, min_samples = 1 as the default configuration.\n",
    "Depending on analytical goals, 0.25 and 0.40 can be used as alternative settings for fine-grained exploration or high-level summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d83674",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
